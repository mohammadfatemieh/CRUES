% !TEX root = ../report.tex

\chapter{Background}\label{litreview}

\todo{Decide if this is being used for a LitReview subsection}
%A literature review was undertaken on all aspects of the project including
%co-operative robotics, computer vision and SLAM both in general and more
%specifically using basic sensors. This was done initially using the Google
%Scholar search engine to search for articles which would be of relevance to
%these topics in isolation and also collectively. These articles, which mainly
%consisted of a variety of journal articles and conference proceedings from
%the IEEE, were then screened further based on their titles and abstracts.
%Priority was given to those with direct relation to the study---for example
%those using ultrasonic sensors to do SLAM or those also using ground vehicles.
%Related articles were also found through citations used within these articles
%in addition to the related articles feature provided by Google Scholar. These
%searches resulted in full investigations of around 4 articles for each of the main
%review topics. When more specific information was required e.g., for specific
%algorithms related to the study, the search term was altered to refine the
%relevant articles. If at any point throughout the study it was felt that more
%reading was required, the selection of articles here were revisited, with
%related articles used to fill in any gaps in knowledge from the original
%searches. \todo{i dont think we need these paragraphs}

\section{Robotics}\label{litreview/robotics}
A robot is ``a machine capable of carrying out a complex series of actions 
automatically''~\cite{robotdef}. 
Robotics is the ``branch of technology which deals with the design, construction, 
operation, and application''~\cite{roboticsdef} of robots. Robotics combines a number of fields from mechanical, 
electrical and software engineering within a single system to achieve its goals. By 
combining the three major disciplines of artificial intelligence, operations 
research, and control theory, a resultant intelligent control system is created~
\cite{saridis1983intelligent} which can be 
used for a wide range of robotic applications.   

\subsection{Control}\label{litreview/robotics/control}  
As the robots in this study are homogeneous and should be able to complete 
tasks individually, control is limited to the control of a single robot in the 
complete system. Robotic mechanisms form the control system for a robot and 
connect the fixed parts of the robot together by joints, allowing motion between 
these fixed parts~\cite{lynch2017modern}. Actuation of the joints, usually 
by motors, imparts forces on the robot which allow it to move and perform a 
variety of tasks~\cite{lynch2017modern}. The movement of these ``actuators'' 
is influenced by a number of sensors which provide the system with information 
about its environment. These sensors can also influence the movement of the 
actuators through feedback from previous movement instructions~\cite{lynch2017modern}.    

Sensors can take many forms and provide information about internal and external 
environmental factors of the robot. External sensors provide information which 
the robot would otherwise find significantly more difficult to discover, one 
such example being range sensing. This can take a number of different forms 
including ultrasound, infra-red, Light Detection And Ranging (LIDAR) and 
binocular computer vision. Each of these sensors use unique methods to determine 
the distance from the robot to another object in its environment. Ultrasound 
sensors use high frequency sound waves which reflect from surfaces and return 
to the sensor. The time taken to return and the speed of sound is used to 
calculate the distance to the object. Infra-red sensors work in a similar 
fashion but with invisible light instead of sound. 

LIDAR is a more advanced use of invisible light to more accurately detect 
distance using more powerful and precise beams of light than in the infra-red 
case~\cite{lidar}. Binocular vision allows depth perception to take place 
similar to that allowed by human vision~\cite{read2005early} by perspective-
based cues which can only be obtained from at least binocular 
vision~\cite{pfautz2002depth}. 

Internal sensors can either be related to the actuators or fixed parts of the 
robot. Those sensors which are connected to the fixed parts of the robot provide 
feedback about the entire robot and its local environment. The Inertial 
Measurement Unit (IMU) provides feedback regarding the acceleration and angular 
velocity with relation to 6 different axis (x, y, z in both linear and angular 
planes) or Degrees of Freedom (DOF). This can be combined with information from 
other sensors in order to reduce the overall error in determining the robot's 
location with relation to its starting position.  

One such sensor is the encoder which is connected to the wheels and provides 
only feedback information about this actuator. These sensors are connected 
directly to the shaft of the motors and provide the control system with the 
actual distance moved by the motors. This allows adjustments to be made and each 
of the wheels to be maintained at a constant speed when utilised by the 
Proportional-Integral-Derivative(PID) controller of a robot.  

\subsection{PID Controller}\label{litreview/robotics/pid}
As mentioned above, PID controllers are a very common solution to problems where the error of the 
system (the difference between the current state and the desired state) can be 
measured. Proportional-Integral-Derivative refers to the 
function of the error with which the output is calculated. The output of the 
system is the summation of a term which is proportional to the error, a term 
which is related to the error integrated over time, and a term which is 
proportional to the rate of change of the error~\cite{aastrom2006advanced}. This is shown by Equation \ref{eqn:pid}.

\begin{equation}
\label{eqn:pid}
O(t) = k_{p}e(t) + k_i\int_{0}^{t}e(t)dt + k_d \frac{\mathrm{d} e(t) }{\mathrm{d} t}
\end{equation}

If $K_d$ and $K_i$ were both 0, and only the P term was active, the output 
would change to reduce the error in the system. For example with a
temperature controller, if the temperature was too low the heater would
turn on, with the difference between the actual temperature and the required 
temperature used to adjust how high it was set. In many systems, this simple 
implementation is adequate, however it has several limitations. 

Consider for instance the temperature controller example where heat is being
lost in the system is equal to the P constant times the error. This would
result in a stable state with a potentially large error. To prevent this,
the I term can be increased. This will increase the longer an error is
present, and preventing stable state errors. 

Again, PI controllers are a common control mechanism, however they often have 
a problem with overshoot due to system inertia. Again considering the 
temperature controller, this is where the heater is set to increase the 
temperature, and the desired temperature is reached. The heater turns off, but 
is still hotter than the rest of the system, causing the system to get too hot. 
This is especially damaging in systems where the control in one direction 
is passive, e.g. the system can actively heat up, but has to wait for heat loss 
to cool down. This problem can be mitigated by increasing the D component. 
This will push the state towards the desired state when the error is increasing 
(e.g. during over-shoot), and pushes the current state away from the desired 
state as the error is reducing as to minimise overshoot before it 
occurs. They do, however, reduce the response speed of the system~\cite{chen2007linear}.

One method of tuning a PID controller is the Ziegler-Nichols method~
\cite{ziegler1942optimum}. This principle originates from before autonomous 
robotic control and has been adapted for this application~
\cite{aastrom2004revisiting}. The method experimentally finds the critical gain 
of $K_p$, $K_u$, from which the frequency of oscillation, $T_u$ can be found. 
These values can then be used to calculate $K_i$ and $K_d$ which results in a 
tuned system. However, many different formulae and definitions of the critical 
gain of $K_p$ exist in literature. This leads to the conclusion that the 
Ziegler-Nichols method is mathematically imperfect and this will have to be 
explored experimentally during the project.      

\section{Cooperative Robotics}\label{litreview/coop}
Co-operative robotics has varied definitions across different papers. One such
definition, which generalises co-operative behaviour in robotics, describes it 
as ``joint collaborative behaviour that is directed toward some goal in which 
there is a common interest or reward''~\cite{barnes1991behaviour}. This 
description fits the objectives of this study more appropriately than the 
specific term swarm robotics,  which has a number of additional requirements, 
including that problem solving should be distributed across the swarm~
\cite{sahin04}. This definition does not apply to this project, as the robots 
designed here are capable of operating autonomously and will be able to solve 
certain tasks individually. In this case, collaboration is used to deliver a 
performance improvement. For this reason, the more general term of co-operative 
robotics will be used throughout. The aim is to reduce the time taken or 
increase performance  of the system over a single-robot system~
\cite{premvuti1990consideration}. Additionally, by creating a decentralised and 
distributed system across a number of homogeneous agents, agent redundancy is 
introduced which can improve the completion rate of tasks, especially in 
potentially volatile environments~\cite{beckers1994local, parker95}.
Co-operative robotics goes beyond the idea of collaborative robotics in 
requiring an additional aspect of intelligence in the communication and 
coordination of the individual agents~\cite{cao1995cooperative}.

\section{SLAM}\label{litreview/slam}
A key challenge in mobile robotics is for the robot to know its own position in the
environment whilst still being able to build a map of its surroundings. 
This is especially true in the absence of external referencing systems
such as GPS to aid in knowing its relative position. This is known as the Simultaneous Localisation And Mapping (SLAM)
problem and has been one of the most extensively researched topics in mobile
robotics over the last two decades~\cite{grisetti2010tutorial}. As the robot's
estimate of its position is affected by both the previous state's uncertainty
and any errors in the current measurement, the uncertainties compound
over time. To rectify this, a map with distinctive landmarks can reduce its
localisation error by revisiting these known areas. This is known as loop closure.

SLAM implementations rely on sensor fusion algorithms as part of their implementation. 
This takes in readings from an array of sensors and calculates an estimated state change
based on the probability of error for each sensor. This effectively allows errors between 
multiple sensors to be cancelled out, resulting in more reliable estimates. A standard 
approach is to use sensor fusion to combine odometry readings from wheel encoders with 
acceleration information obtained from an inertial measurement unit (IMU) to correct for 
errors caused by wheels slipping and sensor imperfections.

There are a large variety of solutions to suit various system requirements, these
can be categorized as either filtering and smoothing. Filtering creates a state estimation 
using the current robot position and the map. The estimate is augmented and improved
by using the new measurements as they become available. Some popular
approaches to filtering are techniques such as Kalman filters, particle filters
and information filters. Smoothing techniques involve a full estimate of the trajectory of
the robot from all available measurements. These typically use least-square error 
minimisation techniques and are used to address the problem known as the full SLAM 
problem which attempts to map the entire path.

The state of the system is known as $x_k$ which is a function that uses the previous 
state to determine the next state. As this can not be perfectly accurate, there will 
be uncertainty in the readings that must be taken into account. As a result, $x_k$,
which is known as the motion model, is defined as
\begin{equation}
x_{k} = f(x_{k-1}, q_{k-1})\,,
\end{equation}
where $q_{k-1}$ is the randomness introduced to the system. As such, this can
also be represented by the probability distribution
\begin{equation}
x_{k} \sim p(x_{k} | x_{k-1})\,.
\end{equation}
Both of these imply that the state is stochastic and depends on the previous
state. The probability distribution emphasises that the current state is
drawn from a distribution of possible states based on the previous state. Given that a perfect sensor is not possible, the current state will also have noise
in the reading. This is known as the measurement model and can be defined as
\begin{equation}
y_{k} = h(x_{k}, r_{k})\,,
\end{equation}
where $r$ represents the uncertainty of the sensor. As
before this can be expressed as an uncertainty model:
\begin{equation}
y_{k} \sim p(y_{k} | y_{k-1})\,.
\end{equation}
It is assumed that the motion and measurement models are Markovian in that
the current state only depends on the previous state. The measurement model only
depends on the current state and no previous values.

By applying Bayes' theorem and marginalisation the current state can be described as
\begin{align}
\label{eqn:predict}
p(x_{k} | y_{1:k-1}) & = \int p(x_{k}|x_{k-1}) p(x_{k-1} | y_{1:k-1}) dx_{k-1} \\
\label{eqn:update}
p(x_{k} | y_{1:k}) &= \frac{ p(y_{k}|x_{k})p(x_{k}|x_{1:k-1})}{ p(y_{k}|y_{1:k-1})}\,.
\end{align}
Equation~\ref{eqn:predict} is known as the predict equation. By integrating over
the previous state, all potential outcomes of the state $x_k$ are
considered. Equation~\ref{eqn:update} is referred to as the update equation,
as the prediction is updated using the new measurement information~\cite{kam1997sensorfusion}.

One of the most common methods of implementing SLAM is filtering using an
Extended Kalman Filter (EKF). An EKF is an efficient, recursive filter
that estimates the state of a dynamic system from a series of noisy measurements~\cite{fox2003bayesian}.
This uses the premise of the predict and update equations as joint probability
distributions. Given variables defined on a probability space, the joint
probability distribution gives the probability that each of the variables falls in any
particular range or set. It uses these techniques to estimates a state vector containing
both the location of landmarks in the map and the robot pose~\cite{huang2007convergence}.


\section{Computer Vision}\label{litreview/cv}
Computer vision is the analysis of digital image or video frames to allow a computer
system to gain a high-level understanding of the 3D environment contained within
the image\cite{CVBallard}. A common application for computer vision is the identification and classification
of objects. Identification generally involves the recognition of features of the
object and the comparison of these features and their relative positions to a
known model of the object. Classification usually involves machine learning
algorithms to build up a definition of the object based on its visible properties\cite{CVpaoletti2018new}.

Computer vision can also be used to triangulate the position of objects in the
field of view by measuring the discrepancy in the object's position in the two camera
frames given a translation matrix relating the two cameras.

Computer vision can be well integrated with SLAM providing a means of both the measure
of distance (if the CV system is bi-ocular) and the identification of distinctive
features in the environment to allow loop closure\cite{CVho2006loop}.
\subsection{Object Detection}\label{litreview/cv/objDet}
\subsubsection{CNN}\label{litreview/cv/objDet/CNN}
A common method for object detection is to use a Convolutional 
Neural Network (CNN)~\cite{schmidhuber2015deep}. This is a deep learning method that 
considers the relative position of pixels in the image. It 
works by scanning a Locally Receptive Field (LRF) across the 
image, and searching this small group of pixels for patterns 
at each position as it moves. This results in a set of 
matrices of outputs, which can then be scanned again. With 
each iteration, the complexity of pattern which can be detected 
increases. The output of these convolutional layers is then 
pooled (combined to reduce size), and used as the input to a 
neural network which can then classify the image.


\subsubsection{Feature Based}\label{litreview/cv/objDet/fb}
Another approach to object detection is feature based. This 
involves the identification and comparison of key points in an 
image of the target object and in the camera frame~\cite{lowe2004distinctive}. There are 
several key point detection algorithms --- SIFT, BRISK and ORB, 
to name a few --- each of which has its own way of describing 
patterns in the pixels and selecting which will be rarer and 
therefore more useful when identifying objects. Each also has 
a method of quantifying the similarity of two matches called a 
distance metric. The algorithm then looks for features in both 
the frame and the object image which score low in the distance 
metric (indicating similarity), filters the matches to remove 
false positives, and then uses the relative positions of the 
matches to estimate an outline of the object in the image 
frame. 

\section{ROS}\label{litreview/ROS}
The Robot Operating System (ROS) is a framework for developing robot
software designed to allow flexible software design. It is a collection of tools, 
libraries and conventions that aim to simplify creating complex and 

robust robotic systems across a variety of platforms~\cite{aboutROS}. 
It was designed with the objective of being as modular and distributed
as possible. This modularity allows the user to be able to use as much or
as little of ROS as they desire, where their own implementation can be
easily fit into the system~\cite{rosForMe}.

ROS uses a peer-to-peer networking topology to allow communication 
throughout the system. These systems consist of a number of processes  
that perform the system's computation called nodes which can  
run across multiple machines. The peer-to-peer topology requires 
a lookup mechanism to allow processes to find other process' addresses at 
runtime so as they can communicate. Nodes communicate by passing messages 
that are data structures of typed fields which can include arbitrarily nested 
structures and arrays~\cite{crick2017rosbridge}.


Nodes can using two distinct ROS frameworks, services and topics. 
Services are synchronous and perform like function
calls in traditional programming languages, where only one node in the 
system can provide a service of a specific name. Alternatively, topics are
asynchronous streams of objects published by a node. Other nodes can 
subscribe by creating  handler function when a new data object is available.
Multiple nodes can concurrently publish and/or subscribe to the same topic and
a single node may publish and/or subscribe to multiple topics.

ROS was also designed to be language-neutral and supports languages 
such as C++, Python and Octave. To support this cross-language 
development, ROS uses a simple, language-neutral Interface Definition 
Language (IDL) to describe the messages sent between modules 
\cite{quigley2009ros}. Code generators for each language then generate 
native implementations which are serialised and de-serialised by ROS 
as messages are sent and received. This results in a language-neutral 
message processing scheme where languages can be used as the programmer 
prefers based on the requirements of that given module. 

There are other alternatives to ROS, such as Yet Another Robot Platform 
(YARP). YARP was designed to attempt to make robot software more stable 
and long-lasting without compromising flexibility to change the sensors, 
processors and actuators. It also communicates using a peer-to-peer 
topology with an extensible family of connection types however, YARP is 
written in C++ and does not support other languages \cite{aboutYARP}.
The YARP model of communication is transport-neutral, meaning the details 
of the underlying networks and protocols in use are decoupled from the 
data flow \cite{exactlyIsYARP}. Compared to ROS, YARP is less widely used.
As a result it does not have the same extensive a range of libraries available 
which implement commonly required functionality for a robotic system.

\section{AI}\label{litreview/maze}
Artificial intelligence is another component of intelligent robotic control and is the 
development of computer systems able to perform tasks normally requiring human intelligence~
\cite{russell2016artificial}. Searching problems, and the algorithms which solve them, are a 
common branch of artificial intelligence into which much research has been undertaken. Search 
algorithms and optimisation algorithms can be thought of as highly similar, and in the case of 
a weighted tree search, which maze exploration can be modelled as, either can be used to solve the problem~\cite{kanal2012search}. 

\subsection{Maze Exploration}\label{litreview/maze/exploration}
The exploration of an unknown environment is a well researched problem in 
robotics. Robot exploration is particularly important for 
environments that are difficult or dangerous for humans. There are many
algorithms that can be used for exploration such as Wall Follower, 
Trémaux's and Pledge.

One of the simplest exploration algorithms is the Wall Follower algorithm, 
also known as the right-hand rule, when prioritising turning right or 
left-hand rule when prioritising turning left. If the maze is simply 
connected, that is, there are no loops in the maze then the Wall Follower 
algorithm is guaranteed to reach a goal/exit if there is one. Otherwise, the 
algorithm will return to the starting point having traversed every corridor at 
least once~\cite{wallFollowerArcBotics}. The steps of the algorithm are 
relatively straightforward. If using the right-hand rule:

\begin{algorithm}
\caption{Wall Follower Algorithm}
\begin{algorithmic}
\REPEAT
\IF{robot can turn right}
  \STATE turn right
\ELSIF{robot can go straight on}
  \STATE go straight on
\ELSIF{robot can turn left}
  \STATE turn left
\ELSE
  \STATE dead end reached, turn 
\ENDIF
\UNTIL{goal is reached}

\end{algorithmic}
\end{algorithm}

These steps ensure to keep a wall on the right hand side of the robot at 
all times. The left-rule is just the opposite where the robot turns left 
if at all possible to keep the wall on the robots' left. Therefore,
this algorithm is inherently inefficiently as it exhaustively searches the
maze. In many cases, one of these algorithms would be significantly quicker
than the other but that is impossible to know without prior knowledge of 
the maze.

An alternative to the Wall Follower algorithm is Pledge's algorithm. This
aims to solve the problem where Wall Follower could be stuck in a loop. An 
example of which is if walls form to create a rectangle in the centre of 
the maze, the robot would continually turn right or left (depending on
algorithm) around that rectangle, never to find the exit. Pledge solves this
by keeping a count of the number of turns made (if not right-angled turns,
then the angle of turn is used instead) as well as the initial direction of
travel. \cite{klein2011pledge}

\begin{algorithm}
\caption{Pledge's Algorithm}
\begin{algorithmic}
\STATE Set angle counter to 0
\REPEAT
\REPEAT
\STATE Walk straight ahead;
\UNTIL {wall hit};
\STATE Turn right;
\REPEAT
\STATE Follow the obstacle's wall;
\UNTIL{angle counter = 0;}
\UNTIL {exit found;}
\end{algorithmic}
\end{algorithm}

Using the initial direction and counting the turns made, allows the 
algorithm to avoid traps such as loops which simple wall followers can be caught in, such as an approximate ``G'' or ``6'' shape.

The Trémaux maze-solving algorithm requires the robot to record its 
path and mark the routes it has taken throughout its navigation routine. Any 
given path  can be unmarked, marked once or marked twice. If a path is marked 
twice that indicates the robot has travelled down it in both directions. The 
robot will not travel down any path marked twice for a third time, therefore 
treating them as dead-ends. Paths without markings are prioritised, before 
choosing those marked once in search of further unmarked paths. If a 
solution is found then the path that is marked only once is the route 
from the goal back to the start point. Otherwise if no solution is found,
all paths in the maze will be marked twice \cite{even2011graph}.
Importantly, this will likely not find the shortest path but it will be 
guaranteed to find one if it exists.

\subsection{Path Finding}\label{litreview/maze/path}
There are many algorithms that can be used to find the shortest path 
through a graph such as Dijkstra's algorithm and A* search. In the 
context of our agents, path finding is likely to be used once 
the goal has been found to return the robot back to its starting 
position. In the case of an unweighted graph (a graph where all edges are 
equivalent to search), one of the simplest algorithm 
is breadth-first search. This explores all neighbours at the same depth 
before moving onto nodes at the next depth level. This would be guaranteed 
to find a path with the shortest number of edges and is $\mathcal{O}(|V| + |E|)$ 
where $|V|$ is the number of vertices and $|E|$ is the number of edges~\cite{cormen2009introduction}
Breadth-first search searches the oldest discovered node first meaning 
a large number of backtracks to reach the oldest discovered node. As 
backtracking in physical space is expensive, this results in a very 
costly search for a single-agent. As more agents are added, the cost of this 
decreases as less backtracking would take place. 

In the case where the edges have a weighting, which in our case would be the 
distance to next junction, Dijkstra's algorithm is one 
of the most commonly used methods for finding the length of shortest path between a specified pair of nodes in the graph. The steps for Dijkstra's algorithm are outlined in Algorithm \ref{alg:Djikstra}.

\begin{algorithm}
\caption{Dijkstra's Algorithm}
\label{alg:Djikstra}
\begin{algorithmic}
\REQUIRE{G = \{vs, es\} : G :: Graph, vs :: List(Vertex), es :: List(Edge)}
\REQUIRE{initial $\in$ vs : initial :: Vertex}
\REQUIRE{successors :: Vertex $\to$ List(Vertex); Finds vertices connected to input}
\REQUIRE{weight :: Edge $\to$ Int; Weighting factor applied to edge}
\REQUIRE{edge :: Vertex $\to$ Vertex $\to$ Edge; Finds edge which links vertices}
\FORALL{v $\in$ vs}
  \STATE{distance[v] $\gets \infty$}
  \STATE{visited[v] $\gets$ False}
\ENDFOR
\STATE {distance[initial] $\gets 0$}
\REPEAT
  \STATE{next $\gets$ v : distance[v] = min(distance) \AND visited[next] = False}
  \IF{no available next}
  	\RETURN distance
  \ENDIF
  \IF{distance[next] = $\infty$}
    \RETURN null
  \ENDIF
  
  \STATE{visited[next] $\gets$ True}
  \FORALL{v $\in$ successors(next) : visited[v] = False}
    \IF{distance[next] + weight(edge(next, v)) < distance[v]}
      \STATE{distance[v] = distance[next] + weight(edge(next, v))}
    \ENDIF
  \ENDFOR
  
\UNTIL{return condition reached}
\end{algorithmic}
\end{algorithm}

This version of Dijkstra's algorithm runs in $\mathcal{O}(|V|^{2})$ 
\cite{xu2007improved}. An improvement to this original algorithm using a 
min-priority queue implemented using a heap, runs in $\mathcal{O}
(|E| + |V|log |V|)$ and was first proposed in~\cite{fredman1987fibonacci}.


Developed initially as an extension of Dijkstra's algorithm, A* is a 
path-finding algorithm that typically achieves better performance by 
use of a heuristic. At each node, A* chooses the node which it believes 
can be used in the shortest path. It does so by choosing the node with 
the lowest value of f, where f is the sum of g and h, where g is the 
distance to the current node plus the known distance to that adjacent 
node and h is the heuristic value from that node to the goal. The heuristic 
value can be found exactly as the first step of the algorithm though 
this is very time consuming so approximate heuristics are used such 
as the Manhattan distance, Diagonal distance and the Euclidean distance. 
