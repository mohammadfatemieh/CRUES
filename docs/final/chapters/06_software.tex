% !TEX root = ../report.tex

\chapter{Software}\label{software}

\todo{Bit in here about overall structure and architecture}



\section{ROS}\label{soft/ROS}

\subsection{Design}\label{soft/ROS/design}

\subsection{Implementation}\label{soft/ROS/impl}

\subsection{Testing}\label{soft/ROS/test}



\section{Communication}\label{soft/comms}
The communication node's requirements were to allow the agents to 
be able to send and receive messages to each other. The structure 
of these messages should allow for any object to be able to be sent 
regardless of the data types, depth or complexity of the objects. 
Each robot should also be able to simultaneously be listening for 
incoming messages whilst sending messages to a different robot. 
With the aim of allowing scalability, the communication system 
should be able to handle robots listening to multiple robots at the 
same time, whilst also being connected to send messages to different 
robots at the same time. 

The communication system also requires a network or communication 
technology to allow all of the robots in the system to be able to 
communicate with each other. Each of the robot's will also require 
a unique identifier to allow sending messages to specific robots 
rather than broadcasting all messages to all robots. 

\subsection{Design}\label{soft/comms/design}
In order to implement these requirements the first decision was the 
method the robots were going to use to communicate. A few options 
for this were considered such as Bluetooth and WiFi. After 
researching  and considering these options, we initially decided to 
use a Wireless Ad-hoc Network (WANET). 

WANET is a wireless network where the nodes can be located anywhere 
globally and does not require any infrastructure such as a router or 
mobile network. The underlying design is such that the nodes believe 
they are part of a single-hop or multiple-hop wireless network at the 
physical layer and the data link layer as part of the MAC sublayer~
\cite{rajesh2015congestion}. The wireless channels are often shared 
and so use carrier sense multiple access protocols to handle multiple 
nodes attempting to use the channel at the same time. This is known 
as link-level congestion and increases packet service time, 
decreasing utilization and overall throughput. Although scalability 
is an important  factor, it was deemed that WANET's handling of 
congestion was sufficient given the anticipated level of 
communication across the system at any time would be low. 

The WANET gives each node on the network its own local IP address. 
Anything that connects to the network can then send messages through 
the network provided it knows this address. As a result, a robot 
needs a way to find this address if it knows who it wishes to send 
a message to. The simplest method for this is to use a lookup table 
that maps the robot's name to their fixed IP in the network, allowing 
all nodes in the network access to this.

After deciding to use WANET, a decision  had to be made in how to format 
the data to send over the network. A few options were available such as 
using JSON, XML or a custom-structure. It was decided the best option was 
to use JavaScript Object Notation (JSON) objects after consultation with 
Dr~Irvine as discussed in Section~\ref{pm/consultations}. JSON is a 
standard data-interchange format that is easy for humans to read and write 
as it uses attribute-value pairs and array data types.

For the structure of the communication module after considering various options, 
a client-server system was decided upon. The client is the node 
responsible for sending the messages whilst the server is responsible 
for listening for incoming messages. As these would be separate nodes, 
these would work independently of each other and so would allow for the 
robot to send and receive messages simultaneously. 

\subsection{Implementation}\label{soft/comms/impl}
Look-up table
First copy of send/receive that caused multi-message issues
The new implementation with the thread-safe code

To implement these requirements a $comms.py$ file was created which contain 
the function definitions and address lookup table that the ROS server and 
client nodes would use to communicate. Firstly a python dictionary of the 
robot's IP addresses as well as our laptop for testing purposes was created. 
A $lookupIP(name)$ function and a $lookupname(ip)$ function were created for 
readability and maintainability. Secondly, a function were needed that could 
create the JSON message ($tojsn()$) and one that could extract the data from 
the message ($fromjson()$). 

\begin{lstlisting}
def tojson(host_ip, hostname, data):
    # receiver ip and hostname, our ip and hostname, classname
    sender_ip = socket.gethostbyname(socket.gethostname())
    header = [host_ip, hostname, sender_ip, 
    Address_lookup.lookupname(sender_ip), type(data).__name__]
    content = [header, data]
    message = json.dump(content, separators=(',', ':'))
    return message

def fromjson(packet):
    message = json.loads(packet)
    try:
        target = message[0][0]
        if target == socket.gethostbyname(socket.gethostname()):
            return message[1]
        else:
            return -1
    except IndexError:
        return -2
\end{lstlisting} 
The header created includes the IP and name of both the sender and the 
receiver as well as the type of python object the data is. The header along 
with the data to be sent is converted to json and returned as a string. When  converting from JSON it checks that it was the intended recipient of the 
message, returning $-1$ to indicate it was not, before returning the data 
object located at index 1 (header is index 0). These are the four helper 
methods used by the send and listen methods.

In order to physically send and receive the data the Python Socket library 
is used. This interface's $sockett()$ function returns a socket object whose 
methods implement the Unix socket system calls. 
\begin{lstlisting}
# data is python object to send
def send(hostname, data):
    host_ip = lookupip(hostname) # The remote host
    port_number = 8001 # The same port as used by the server
    message = tojson(host_ip, hostname, data)
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    if not s.connect_ex((host_ip, port_number)):
        s.sendall(message) # Sends string (of JSON)
        s.close()
\end{lstlisting}
The send function looks up the IP of the destination and gets the JSON object 
of the message. It then attempts to connect using the $connect_ex()$ which 
returns 0 if successful. If so then it can use the socket methods to send the 
data and then close the connection. 

\begin{lstlisting}
def listen():
    PORT = 8001 # Arbitrary non-privileged port
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.bind(('0.0.0.0', PORT))
    s.listen(2)
    conn, addr = s.accept()
    packets = '' 
    while 1:
        packet = conn.recv(1024)
        if not packet:
            break
        packets += packet
    conn.close()
    message = fromjson(packets)
    return message
\end{lstlisting}
When listening for incoming messages, the created socket object must bind to 
an IP address and port number. The address of 0.0.0.0 results in it listening 
to any incoming messages. The $listen()$ function starts the node listening 
whilst setting the number of queued connections allowed. In this case it is 
set to 2 but can be increased when scaling the system to use many more agents. 
Once the socket  accepts a connection, we can continually store the packets 
until no more data is received. After which the connection can be closed and 
the data read from the JSON strings and returned.

This implementation was set up and initially tested between a laptop and a Pi 
by remotely connecting to the Pi. When this succeeded in sending multiple 
messages between them, we remotely connected to another Pi and attempted to 
have them send messages back and forth to each other. Again this was successful 
and so this demonstrated the basic functionality of the communication system was 
working.

When undertaking more extensive testing, an important issue with the previous 
code was found. When nodes were sending messages to each other simultaneously 
at least one of the nodes would fail. For example, if Blinky sends a message to  
Clyde but before the message has finished sending, Clyde sends a message to 
Blinky then the receiver of Clyde crashes and Blinky never receives the message. 
If Clyde were to send to a third robot, Inky, then Clyde's receiver would still 
fail as would one of either Blinky or Inky. 

As a result of this bug, the implementation would have to be changed to handle 
multiple connections properly. Various potential solutions were discussed, 
such as using multiple ports so as not to kill the socket connection when 
attempting to connect again or to use a multi-connection selector as part of 
the server to handle multiple requests \cite{multiconnectionServer}. Instead 
of these solutions, a thread-safe version of the existing code base was 
designed.  If the server can always be listening for incoming messages by 
utilising multiple threads then there would be no downtime of the system and 
thus each message would be successfully sent. 

This was implemented by defining ThreadedTCPServer and ThreadedTCPRequestHandler  
classes to be used by the listener as shown in SocketServer documentation~\cite{socketServerDocs}.
\begin{lstlisting}
class ThreadedTCPRequestHandler(SocketServer.BaseRequestHandler):
    def messageHandler(self, x):
        print x

    def handle(self):
        data = self.request.recv(1024)
        message = fromjson(data)
        self.messageHandler(message)

class ThreadedTCPServer(SocketServer.ThreadingMixIn, SocketServer.TCPServer):
    pass
\end{lstlisting}
The $listen()$ function is changed to take in a handler parameter. This is 
passed a function which is used instead of the messageHandler function in 
the ThreadedTCPRequetHandler before it is used to create a ThreadedTCPServer 
object as shown.
\begin{lstlisting}
def listen(handler):
    ThreadedTCPRequestHandler.messageHandler = handler
    HOST, PORT = "0.0.0.0", 8001
    server = ThreadedTCPServer((HOST, PORT), ThreadedTCPRequestHandler)
    ip, port = server.server_address
    # Start a thread with the server -- that thread will then start one
    # more thread for each request
    server_thread = threading.Thread(target=server.serve_forever)
    # Exit the server thread when the main thread terminates
    server_thread.daemon = True
    server_thread.start()
    return server
\end{lstlisting}
The handler object passed is a function that will solely publish the 
message contents so the relevant subscribers can use the data received 
from the other agent. As a new thread is being created for each request 
there should be no node crashes from having the process interrupted as 
it will be happening on a different thread.
\todo{Is testing for just the final designed testing - cause this goes impl - testing  impl - testing and not sure how we want to handle that}

\subsection{Testing}\label{soft/comms/test}

In order to test this version it was important to first ensure that the 
working functionality from the previous version still worked. Therefore 
the same initial tests were applied to this implementation which passed 
as expected. In order to test whether this was thread-safe, a number of 
tests were executed. The first test involved creating a loop that would 
send 100 messages from Blinky to Clyde. When this succeeded without any 
node crashes, the test was repeat but with Clyde sending messages to Blinky 
simultaneously. This previously would have crashed the nodes but with the 
server's listening on separate threads for each request, this was handled 
successfully. This test was repeated with Clyde sending messages to Inky 
instead of Clyde. This too was successful with the messages being received 
without any being lost. The test was repeated but the limit on the number of 
messages being send was removed, and so the messages would, in theory, 
continue to create new threads to listen to the incoming messages. This 
worked initially, but due to there being no delay in between sending messages, 
thousands of threads were being created quickly. This resulted in the node 
crashing as the thread limit had been reached, however, this happened after 
over 50 thousand messages in quick succession (due to no delay). As a result, 
this was determined to be the upper limit of this system, that with this set 
up would never be close to reached and so it was determined that the system 
was sufficiently thread-safe to be used. 


\section{SLAM \& Sensor Fusion}\label{soft/SLAM}

\subsection{Design}\label{soft/SLAM/design}

\subsection{Implementation}\label{soft/SLAM/impl}

\subsection{Testing}\label{soft/SLAM/test}



\section{Computer Vision}\label{soft/cv}

\subsection{Design}\label{soft/cv/design}

\subsection{Implementation}\label{soft/cv/impl}

\subsection{Testing}\label{soft/cv/test}



\section{AI \& Control Modules}\label{soft/ai}

\subsection{Design}\label{soft/ai/design}

\subsection{Implementation}\label{soft/ai/impl}

\subsection{Testing}\label{soft/ai/test}